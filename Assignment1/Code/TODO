
Add dependency injection or some kind of configuration lookup for applying different parameters for different datasets

Move multirun hyperparameter_validation from boosted_test to base_test
    - reimplement all other tests to use this method

Change dataset split seed when appropriate
    - random_state is only keeping constant the makeup of the data sets when split

Dataset balancing investigation/graphing

Get LC to add more than 100 samples

Listen to office hours

1. Decision Tree: pruning

All grading is done with the context of the results
    - giving descriptions of algorithms alone isn't useful

The reader understands the basics of ML algorithms

Don't provide a table of context, manage space well
    - use dual column
